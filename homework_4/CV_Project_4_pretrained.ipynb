{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gg9LOzN04dI"
      },
      "source": [
        "\n",
        "# This is a collaboratory, where you can find the code of the final project (Project 4) of the course : **Computer Vision** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL0MYDamMfSG",
        "outputId": "2b13a2e3-ea2f-472c-b278-713f642a7121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive :\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My-899h3OLMU"
      },
      "outputs": [],
      "source": [
        "# Unzip the dataset and save it to the path \"/content/imagedb_btsd\" :\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/MyDrive/cv_proj_4_dataset/imagedb_btsd.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/imagedb_btsd')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za7fdIZxUjWF"
      },
      "outputs": [],
      "source": [
        "# Select the folder \"imagedb\" as the training folder\n",
        "# and the folder \"imagedb_test\" as the testing folder :\n",
        "\n",
        "base_dir = '/content/imagedb_btsd'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'imagedb')\n",
        "test_dir = os.path.join(base_dir, 'imagedb_test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UQwZlm3dMGa"
      },
      "source": [
        "Using transfer learning :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLhphCy3bzsn",
        "outputId": "fcae1e2f-dc3f-4211-d96e-37dd2c296efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications import vgg16\n",
        "#Load the VGG model\n",
        "vgg_conv = vgg16.VGG16(weights='imagenet', \n",
        "                 include_top=False, \n",
        "                 input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nid7iO8OhGY2"
      },
      "outputs": [],
      "source": [
        "# # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# vgg_conv2 = vgg16.VGG16(weights='imagenet', \n",
        "#                  include_top=True)\n",
        "\n",
        "# for layer in vgg_conv2.layers:\n",
        "#     print(layer, layer.trainable)\n",
        "\n",
        "# from keras import models\n",
        "\n",
        "# model2 = models.Sequential()\n",
        " \n",
        "# # Add the vgg convolutional base model\n",
        "# model2.add(vgg_conv2)\n",
        "\n",
        "# model2.summary()\n",
        " \n",
        "# # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwkREEQ5dXgl",
        "outputId": "1a68a7ab-be18-4df0-9d3b-251ffb4798fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f5273790c10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f526a3983d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5267bbd110> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f52602d3290> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602d5550> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602de1d0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f52602d5190> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5267b59550> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602e6390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f526846d250> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f52602d3b90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602f0310> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602fa290> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602f4b10> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f52602fef10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5260308190> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f526030e610> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f52602d5610> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f526030b150> True\n"
          ]
        }
      ],
      "source": [
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f1lgjcmdapG",
        "outputId": "5b530461-51dc-4592-ed7d-cde785d3dfef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              33555456  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                34850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,304,994\n",
            "Trainable params: 40,669,730\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(34, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKc9H22CdfLY",
        "outputId": "22f09c96-01c0-4f69-ae50-9e53c1b50b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2457 images belonging to 34 classes.\n",
            "Found 599 images belonging to 34 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range = 90, preprocessing_function=vgg16.preprocess_input, validation_split=0.2)\n",
        "#train_datagen  = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=40,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    # color_mode='grayscale',\n",
        "                                                    target_size=(256,256),\n",
        "                                                    shuffle=True,\n",
        "                                                    subset='training', seed=1)     \n",
        "# --------------------\n",
        "# Flow validation images in batches using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  train_datagen.flow_from_directory(train_dir,\n",
        "                                                        batch_size=40,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        #  color_mode='grayscale',\n",
        "                                                         target_size=(256,256),\n",
        "                                                        subset='validation', seed=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS4Xk04ARFVQ"
      },
      "outputs": [],
      "source": [
        "model_name = 'pretrained_VGG16_batch_40_epochs_60'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqjTh7L9RHem"
      },
      "outputs": [],
      "source": [
        "# Apply callbacks :\n",
        "\n",
        "my_callbacks = []\n",
        "\n",
        "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'' + model_name + '.hdf5', save_best_only=True, verbose=1)\n",
        "my_callbacks.append(save_best_callback)\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\n",
        "my_callbacks.append(early_stop_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoKCP8g8eA97",
        "outputId": "23511269-f4fd-4a75-d331-668515239417"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 3.8761 - acc: 0.2291\n",
            "Epoch 00001: val_loss improved from inf to 2.02838, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 80s 969ms/step - loss: 3.8761 - acc: 0.2291 - val_loss: 2.0284 - val_acc: 0.4290\n",
            "Epoch 2/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.6398 - acc: 0.5425\n",
            "Epoch 00002: val_loss improved from 2.02838 to 1.14018, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 46s 754ms/step - loss: 1.6398 - acc: 0.5425 - val_loss: 1.1402 - val_acc: 0.6912\n",
            "Epoch 3/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.9980 - acc: 0.7106\n",
            "Epoch 00003: val_loss improved from 1.14018 to 0.77712, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 47s 757ms/step - loss: 0.9980 - acc: 0.7106 - val_loss: 0.7771 - val_acc: 0.7780\n",
            "Epoch 4/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.7118 - acc: 0.7843\n",
            "Epoch 00004: val_loss improved from 0.77712 to 0.62399, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 46s 750ms/step - loss: 0.7118 - acc: 0.7843 - val_loss: 0.6240 - val_acc: 0.8114\n",
            "Epoch 5/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5578 - acc: 0.8429\n",
            "Epoch 00005: val_loss improved from 0.62399 to 0.40948, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 47s 756ms/step - loss: 0.5578 - acc: 0.8429 - val_loss: 0.4095 - val_acc: 0.8865\n",
            "Epoch 6/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3899 - acc: 0.8836\n",
            "Epoch 00006: val_loss did not improve from 0.40948\n",
            "61/61 [==============================] - 45s 733ms/step - loss: 0.3899 - acc: 0.8836 - val_loss: 0.4224 - val_acc: 0.8831\n",
            "Epoch 7/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.2811 - acc: 0.9166\n",
            "Epoch 00007: val_loss improved from 0.40948 to 0.29429, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 47s 768ms/step - loss: 0.2811 - acc: 0.9166 - val_loss: 0.2943 - val_acc: 0.9149\n",
            "Epoch 8/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.2341 - acc: 0.9316\n",
            "Epoch 00008: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 727ms/step - loss: 0.2341 - acc: 0.9316 - val_loss: 0.3760 - val_acc: 0.9115\n",
            "Epoch 9/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.2007 - acc: 0.9422\n",
            "Epoch 00009: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 728ms/step - loss: 0.2007 - acc: 0.9422 - val_loss: 0.2962 - val_acc: 0.9199\n",
            "Epoch 10/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1602 - acc: 0.9512\n",
            "Epoch 00010: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 726ms/step - loss: 0.1602 - acc: 0.9512 - val_loss: 0.3333 - val_acc: 0.9149\n",
            "Epoch 11/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1782 - acc: 0.9508\n",
            "Epoch 00011: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 728ms/step - loss: 0.1782 - acc: 0.9508 - val_loss: 0.3545 - val_acc: 0.8982\n",
            "Epoch 12/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1735 - acc: 0.9503\n",
            "Epoch 00012: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 733ms/step - loss: 0.1735 - acc: 0.9503 - val_loss: 0.3753 - val_acc: 0.8965\n",
            "Epoch 13/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1629 - acc: 0.9524\n",
            "Epoch 00013: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 743ms/step - loss: 0.1629 - acc: 0.9524 - val_loss: 0.4381 - val_acc: 0.9199\n",
            "Epoch 14/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1099 - acc: 0.9646\n",
            "Epoch 00014: val_loss did not improve from 0.29429\n",
            "61/61 [==============================] - 45s 731ms/step - loss: 0.1099 - acc: 0.9646 - val_loss: 0.3847 - val_acc: 0.9232\n",
            "Epoch 15/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1154 - acc: 0.9654\n",
            "Epoch 00015: val_loss improved from 0.29429 to 0.27146, saving model to pretrained_VGG16_batch_40_epochs_60.hdf5\n",
            "61/61 [==============================] - 46s 756ms/step - loss: 0.1154 - acc: 0.9654 - val_loss: 0.2715 - val_acc: 0.9332\n",
            "Epoch 16/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1092 - acc: 0.9662\n",
            "Epoch 00016: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 730ms/step - loss: 0.1092 - acc: 0.9662 - val_loss: 0.3238 - val_acc: 0.9382\n",
            "Epoch 17/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0990 - acc: 0.9715\n",
            "Epoch 00017: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 727ms/step - loss: 0.0990 - acc: 0.9715 - val_loss: 0.3509 - val_acc: 0.9249\n",
            "Epoch 18/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0823 - acc: 0.9735\n",
            "Epoch 00018: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 728ms/step - loss: 0.0823 - acc: 0.9735 - val_loss: 0.2716 - val_acc: 0.9432\n",
            "Epoch 19/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0812 - acc: 0.9784\n",
            "Epoch 00019: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 733ms/step - loss: 0.0812 - acc: 0.9784 - val_loss: 0.3448 - val_acc: 0.9282\n",
            "Epoch 20/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0635 - acc: 0.9796\n",
            "Epoch 00020: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 732ms/step - loss: 0.0635 - acc: 0.9796 - val_loss: 0.3048 - val_acc: 0.9282\n",
            "Epoch 21/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0375 - acc: 0.9874\n",
            "Epoch 00021: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 729ms/step - loss: 0.0375 - acc: 0.9874 - val_loss: 0.3170 - val_acc: 0.9349\n",
            "Epoch 22/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9833\n",
            "Epoch 00022: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 731ms/step - loss: 0.0473 - acc: 0.9833 - val_loss: 0.3318 - val_acc: 0.9432\n",
            "Epoch 23/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0924 - acc: 0.9768\n",
            "Epoch 00023: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 728ms/step - loss: 0.0924 - acc: 0.9768 - val_loss: 0.3495 - val_acc: 0.9316\n",
            "Epoch 24/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0653 - acc: 0.9841\n",
            "Epoch 00024: val_loss did not improve from 0.27146\n",
            "61/61 [==============================] - 45s 733ms/step - loss: 0.0653 - acc: 0.9841 - val_loss: 0.3202 - val_acc: 0.9399\n",
            "Epoch 25/60\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0594 - acc: 0.9829\n",
            "Epoch 00025: val_loss did not improve from 0.27146\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "61/61 [==============================] - 45s 727ms/step - loss: 0.0594 - acc: 0.9829 - val_loss: 0.3029 - val_acc: 0.9316\n",
            "Epoch 00025: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.adam_v2.Adam(learning_rate=1e-4),\n",
        "              metrics=['acc'])\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=60,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=1,\n",
        "      callbacks = my_callbacks)\n",
        " \n",
        "# # Save the model\n",
        "# model_name = 'pretrained_VGG16_batch_40_epochs_60'\n",
        "# model.save(model_name + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "aqyBPHdC9Oox",
        "outputId": "7c1b0790-b1ba-42be-96b1-38355a3b7e7f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/CV_Project_4_saved_models/pretrained_VGG16_batch_40_epochs_60'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Saving the model to a google drive folder :\n",
        "\n",
        "import shutil\n",
        "shutil.copy('/content/'+ model_name +'.hdf5','/content/drive/MyDrive/CV_Project_4_saved_models/'+ model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzDcHPt7Fv2A",
        "outputId": "ff6fc711-57a3-4743-b42f-3dc83d014bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2149 images belonging to 34 classes.\n",
            "215/215 [==============================] - 39s 162ms/step - loss: 3.1641 - acc: 0.0847\n"
          ]
        }
      ],
      "source": [
        "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# --------------------\n",
        "# Flow validation images in batches using test_datagen generator\n",
        "# --------------------\n",
        "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
        "                                                        batch_size=10,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        #  color_mode='grayscale',\n",
        "                                                         target_size=(256,256))\n",
        "# Testing the CNN on testing data : \n",
        "loss, acc = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu5dP5vq9wA_"
      },
      "outputs": [],
      "source": [
        "# # Loading the model from the google drive folder : \n",
        "\n",
        "# model_loaded = models.load_model('/content/drive/MyDrive/CV_Project_4_saved_models/' + model_name)\n",
        "# model_loaded.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CV_Project_4_pretrained.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMOzsF6bVZGB9Atz6Nmiws"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}