{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# This is a collaboratory, where you can find the code with the network from scratch of the final project (Project 4) of the course : **Computer Vision** "
      ],
      "metadata": {
        "id": "03IWgtOFCvAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1efK3dBnSNsW",
        "outputId": "2eb39e83-6e2c-4c7b-eb80-87ac86cf99b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive :\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UES-_QQCSXQM"
      },
      "outputs": [],
      "source": [
        "# Unzip the dataset and save it to the path \"/content/imagedb_btsd\" :\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/MyDrive/cv_proj_4_dataset/imagedb_btsd.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/imagedb_btsd')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "23UpZ_4lTZGN"
      },
      "outputs": [],
      "source": [
        "# Select the folder \"imagedb\" as the training folder\n",
        "# and the folder \"imagedb_test\" as the testing folder :\n",
        "\n",
        "base_dir = '/content/imagedb_btsd'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'imagedb')\n",
        "test_dir = os.path.join(base_dir, 'imagedb_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAg9eIeSShP9",
        "outputId": "58b80e92-a748-4f6d-b294-d26746d0063b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                34850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,856,162\n",
            "Trainable params: 25,856,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding=\"valid\", activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding=\"valid\", activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding=\"valid\", activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(34, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=optimizers.adam_v2.Adam(learning_rate=1e-4),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWGtpHkotMbZ",
        "outputId": "448e31c1-09d3-48a4-f2bb-81cb621a9c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.layers.convolutional.Conv2D object at 0x7fedc3b8f950> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fedc3b8f910> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fed4018dcd0> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fed401b7c90> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fed401e4350> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fed40162610> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fed40169190> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fed4016c450> True\n",
            "<keras.layers.core.flatten.Flatten object at 0x7fed4016fd90> True\n",
            "<keras.layers.core.dense.Dense object at 0x7fed40162390> True\n",
            "<keras.layers.core.dropout.Dropout object at 0x7fed40169110> True\n",
            "<keras.layers.core.dense.Dense object at 0x7fed40169d50> True\n"
          ]
        }
      ],
      "source": [
        "# check this :\n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in model.layers:\n",
        "    print(layer, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWDZ2ZpnShK9",
        "outputId": "c7ebd981-91b5-4764-a101-f45d3196b41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2457 images belonging to 34 classes.\n",
            "Found 599 images belonging to 34 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range = 90,\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip = True,\n",
        "                                   brightness_range=[0.2,1.0],\n",
        "                                   zoom_range=[0.5,1.0],                                   \n",
        "                                   validation_split=0.2)\n",
        "                                  #  preprocessing_function = preprocess_func)\n",
        "                                  \n",
        "#train_datagen  = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=40,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    # color_mode='grayscale',\n",
        "                                                    target_size=(256,256),\n",
        "                                                    shuffle=True,\n",
        "                                                    subset='training', seed=1)     \n",
        "# --------------------\n",
        "# Flow validation images in batches using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  train_datagen.flow_from_directory(train_dir,\n",
        "                                                          batch_size=40,\n",
        "                                                          class_mode='categorical',\n",
        "                                                          # color_mode='grayscale',\n",
        "                                                          target_size=(256,256),\n",
        "                                                          subset='validation', seed=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ueQ8b0eukBoi"
      },
      "outputs": [],
      "source": [
        "# Apply callbacks :\n",
        "\n",
        "import datetime \n",
        "import tensorflow as tf\n",
        "  \n",
        "my_callbacks = []\n",
        "\n",
        "# logdir = os.path.join(\"/content/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "# my_callbacks.append(tensorboard_callback)\n",
        "\n",
        "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'model_from_scratch_best.hdf5', save_best_only=True, verbose=1)\n",
        "my_callbacks.append(save_best_callback)\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\n",
        "my_callbacks.append(early_stop_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5iuGSf2TzI_",
        "outputId": "6d0aac14-944c-4218-bc58-3c2206bca5d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 6.2334 - accuracy: 0.2499\n",
            "Epoch 00001: val_loss improved from inf to 1.93122, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 57s 797ms/step - loss: 6.2334 - accuracy: 0.2499 - val_loss: 1.9312 - val_accuracy: 0.4992\n",
            "Epoch 2/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 2.0480 - accuracy: 0.4632\n",
            "Epoch 00002: val_loss improved from 1.93122 to 1.50329, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 754ms/step - loss: 2.0480 - accuracy: 0.4632 - val_loss: 1.5033 - val_accuracy: 0.6177\n",
            "Epoch 3/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.6419 - accuracy: 0.5710\n",
            "Epoch 00003: val_loss improved from 1.50329 to 1.21323, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 753ms/step - loss: 1.6419 - accuracy: 0.5710 - val_loss: 1.2132 - val_accuracy: 0.7078\n",
            "Epoch 4/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.3679 - accuracy: 0.6370\n",
            "Epoch 00004: val_loss improved from 1.21323 to 1.03603, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 749ms/step - loss: 1.3679 - accuracy: 0.6370 - val_loss: 1.0360 - val_accuracy: 0.7312\n",
            "Epoch 5/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.1917 - accuracy: 0.6846\n",
            "Epoch 00005: val_loss improved from 1.03603 to 0.86368, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 744ms/step - loss: 1.1917 - accuracy: 0.6846 - val_loss: 0.8637 - val_accuracy: 0.8013\n",
            "Epoch 6/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.0801 - accuracy: 0.7102\n",
            "Epoch 00006: val_loss improved from 0.86368 to 0.81014, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 45s 741ms/step - loss: 1.0801 - accuracy: 0.7102 - val_loss: 0.8101 - val_accuracy: 0.8080\n",
            "Epoch 7/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.7354\n",
            "Epoch 00007: val_loss improved from 0.81014 to 0.79812, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 746ms/step - loss: 0.9642 - accuracy: 0.7354 - val_loss: 0.7981 - val_accuracy: 0.7846\n",
            "Epoch 8/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.8980 - accuracy: 0.7562\n",
            "Epoch 00008: val_loss improved from 0.79812 to 0.64899, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 742ms/step - loss: 0.8980 - accuracy: 0.7562 - val_loss: 0.6490 - val_accuracy: 0.8347\n",
            "Epoch 9/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.7796 - accuracy: 0.7941\n",
            "Epoch 00009: val_loss did not improve from 0.64899\n",
            "61/61 [==============================] - 45s 731ms/step - loss: 0.7796 - accuracy: 0.7941 - val_loss: 0.7682 - val_accuracy: 0.7947\n",
            "Epoch 10/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.7561 - accuracy: 0.7912\n",
            "Epoch 00010: val_loss improved from 0.64899 to 0.59185, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 745ms/step - loss: 0.7561 - accuracy: 0.7912 - val_loss: 0.5919 - val_accuracy: 0.8598\n",
            "Epoch 11/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.8075\n",
            "Epoch 00011: val_loss improved from 0.59185 to 0.53927, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 746ms/step - loss: 0.6754 - accuracy: 0.8075 - val_loss: 0.5393 - val_accuracy: 0.8598\n",
            "Epoch 12/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.8189\n",
            "Epoch 00012: val_loss did not improve from 0.53927\n",
            "61/61 [==============================] - 45s 735ms/step - loss: 0.6345 - accuracy: 0.8189 - val_loss: 0.5504 - val_accuracy: 0.8614\n",
            "Epoch 13/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.8356\n",
            "Epoch 00013: val_loss improved from 0.53927 to 0.53428, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 748ms/step - loss: 0.6086 - accuracy: 0.8356 - val_loss: 0.5343 - val_accuracy: 0.8564\n",
            "Epoch 14/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.8409\n",
            "Epoch 00014: val_loss improved from 0.53428 to 0.46091, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 749ms/step - loss: 0.5685 - accuracy: 0.8409 - val_loss: 0.4609 - val_accuracy: 0.8915\n",
            "Epoch 15/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.8575\n",
            "Epoch 00015: val_loss did not improve from 0.46091\n",
            "61/61 [==============================] - 45s 737ms/step - loss: 0.5324 - accuracy: 0.8575 - val_loss: 0.4674 - val_accuracy: 0.8698\n",
            "Epoch 16/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8551\n",
            "Epoch 00016: val_loss did not improve from 0.46091\n",
            "61/61 [==============================] - 45s 740ms/step - loss: 0.5280 - accuracy: 0.8551 - val_loss: 0.4693 - val_accuracy: 0.8765\n",
            "Epoch 17/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.8519\n",
            "Epoch 00017: val_loss did not improve from 0.46091\n",
            "61/61 [==============================] - 45s 740ms/step - loss: 0.5025 - accuracy: 0.8519 - val_loss: 0.4613 - val_accuracy: 0.8798\n",
            "Epoch 18/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.8698\n",
            "Epoch 00018: val_loss did not improve from 0.46091\n",
            "61/61 [==============================] - 46s 744ms/step - loss: 0.4855 - accuracy: 0.8698 - val_loss: 0.4984 - val_accuracy: 0.8514\n",
            "Epoch 19/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.8763\n",
            "Epoch 00019: val_loss did not improve from 0.46091\n",
            "61/61 [==============================] - 45s 742ms/step - loss: 0.4536 - accuracy: 0.8763 - val_loss: 0.4992 - val_accuracy: 0.8681\n",
            "Epoch 20/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8730\n",
            "Epoch 00020: val_loss improved from 0.46091 to 0.42552, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 757ms/step - loss: 0.4720 - accuracy: 0.8730 - val_loss: 0.4255 - val_accuracy: 0.8898\n",
            "Epoch 21/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.8869\n",
            "Epoch 00021: val_loss did not improve from 0.42552\n",
            "61/61 [==============================] - 45s 739ms/step - loss: 0.4004 - accuracy: 0.8869 - val_loss: 0.4270 - val_accuracy: 0.8848\n",
            "Epoch 22/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.8832\n",
            "Epoch 00022: val_loss improved from 0.42552 to 0.40451, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 748ms/step - loss: 0.4265 - accuracy: 0.8832 - val_loss: 0.4045 - val_accuracy: 0.8715\n",
            "Epoch 23/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8893\n",
            "Epoch 00023: val_loss did not improve from 0.40451\n",
            "61/61 [==============================] - 45s 733ms/step - loss: 0.3987 - accuracy: 0.8893 - val_loss: 0.4685 - val_accuracy: 0.8681\n",
            "Epoch 24/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8974\n",
            "Epoch 00024: val_loss did not improve from 0.40451\n",
            "61/61 [==============================] - 45s 733ms/step - loss: 0.3832 - accuracy: 0.8974 - val_loss: 0.4199 - val_accuracy: 0.9048\n",
            "Epoch 25/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8982\n",
            "Epoch 00025: val_loss did not improve from 0.40451\n",
            "61/61 [==============================] - 45s 736ms/step - loss: 0.3728 - accuracy: 0.8982 - val_loss: 0.4277 - val_accuracy: 0.8715\n",
            "Epoch 26/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8946\n",
            "Epoch 00026: val_loss did not improve from 0.40451\n",
            "61/61 [==============================] - 45s 734ms/step - loss: 0.3749 - accuracy: 0.8946 - val_loss: 0.4288 - val_accuracy: 0.8731\n",
            "Epoch 27/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.9039\n",
            "Epoch 00027: val_loss improved from 0.40451 to 0.35954, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 752ms/step - loss: 0.3603 - accuracy: 0.9039 - val_loss: 0.3595 - val_accuracy: 0.9082\n",
            "Epoch 28/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.9162\n",
            "Epoch 00028: val_loss did not improve from 0.35954\n",
            "61/61 [==============================] - 46s 744ms/step - loss: 0.3002 - accuracy: 0.9162 - val_loss: 0.3868 - val_accuracy: 0.8982\n",
            "Epoch 29/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.9072\n",
            "Epoch 00029: val_loss did not improve from 0.35954\n",
            "61/61 [==============================] - 45s 741ms/step - loss: 0.3515 - accuracy: 0.9072 - val_loss: 0.3873 - val_accuracy: 0.9032\n",
            "Epoch 30/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.9064\n",
            "Epoch 00030: val_loss improved from 0.35954 to 0.35359, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 756ms/step - loss: 0.3277 - accuracy: 0.9064 - val_loss: 0.3536 - val_accuracy: 0.9098\n"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              # steps_per_epoch=50,\n",
        "                              steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
        "                              epochs=30,\n",
        "                              validation_steps=15,\n",
        "                              verbose=1,\n",
        "                              callbacks=my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BZANTHekSznu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1174031a-4e3c-4a1d-df1c-dfc7788a4ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2149 images belonging to 34 classes.\n"
          ]
        }
      ],
      "source": [
        "# test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen  = ImageDataGenerator()\n",
        "# --------------------\n",
        "# Flow testing images in batches using test_datagen generator\n",
        "# --------------------\n",
        "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
        "                                                   batch_size=10,\n",
        "                                                   class_mode='categorical',\n",
        "                                                  #  color_mode='grayscale',\n",
        "                                                   target_size=(256,256))\n",
        "# # Testing the CNN on testing data : \n",
        "# loss, acc = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q3PTISh9XtGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d949efd2-45ce-4852-a5b7-432d9cfca829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 5s 20ms/step - loss: 1.5507 - accuracy: 0.7073\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Testing the CNN on testing data : \n",
        "loss, acc = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading the best state model from the content folder : \n",
        "\n",
        "model_saved = models.load_model('/content/model_from_scratch_best.hdf5')\n",
        "model_saved.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmXJP6VsLlS9",
        "outputId": "a07f5e45-771a-4bd4-f1e6-267c6a1a8656"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                34850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,856,162\n",
            "Trainable params: 25,856,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " loss_saved, acc_saved = model_saved.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD96ihm6LwpB",
        "outputId": "758ded9f-d1d0-411c-c87e-984fb49d9ae8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 3s 14ms/step - loss: 1.5507 - accuracy: 0.7073\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CV_Project_4_NOT_pretrained.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIrEthLnMJ0TuN3AJlQDHv"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}