{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1efK3dBnSNsW",
        "outputId": "5cdcaf44-7587-4b73-a7f7-b141ced2da1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive :\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UES-_QQCSXQM"
      },
      "outputs": [],
      "source": [
        "# Unzip the dataset and save it to the path \"/content/imagedb_btsd\" :\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/MyDrive/cv_proj_4_dataset/imagedb_btsd.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/imagedb_btsd')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "23UpZ_4lTZGN"
      },
      "outputs": [],
      "source": [
        "# Select the folder \"imagedb\" as the training folder\n",
        "# and the folder \"imagedb_test\" as the testing folder :\n",
        "\n",
        "base_dir = '/content/imagedb_btsd'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'imagedb')\n",
        "test_dir = os.path.join(base_dir, 'imagedb_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAg9eIeSShP9",
        "outputId": "dfeb10e7-c3bc-4ef6-9bad-a9febd3b44ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                34850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,856,162\n",
            "Trainable params: 25,856,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding=\"valid\", activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding=\"valid\", activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding=\"valid\", activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(34, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=optimizers.adam_v2.Adam(learning_rate=1e-4),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWGtpHkotMbZ",
        "outputId": "d3d80584-d5bf-4c9c-9911-6ac09e7d9a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.layers.convolutional.Conv2D object at 0x7f46ea3e6f10> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f47e0232390> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47dc5037d0> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f47dc53a310> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f476a612510> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f47dc482fd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47dc482f50> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f47dc497a90> True\n",
            "<keras.layers.core.flatten.Flatten object at 0x7f47dc49d190> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f47dc4a1e50> True\n",
            "<keras.layers.core.dropout.Dropout object at 0x7f47dc503c90> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f47dc574650> True\n"
          ]
        }
      ],
      "source": [
        "# check this :\n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in model.layers:\n",
        "    print(layer, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWDZ2ZpnShK9",
        "outputId": "0df17845-1bb8-4dee-8cec-e7122a1f8094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2457 images belonging to 34 classes.\n",
            "Found 599 images belonging to 34 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range = 90,\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip = True,\n",
        "                                   brightness_range=[0.2,1.0],\n",
        "                                   zoom_range=[0.5,1.0],                                   \n",
        "                                   validation_split=0.2)\n",
        "                                  #  preprocessing_function = preprocess_func)\n",
        "                                  \n",
        "#train_datagen  = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=40,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    # color_mode='grayscale',\n",
        "                                                    target_size=(256,256),\n",
        "                                                    shuffle=True,\n",
        "                                                    subset='training', seed=1)     \n",
        "# --------------------\n",
        "# Flow validation images in batches using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  train_datagen.flow_from_directory(train_dir,\n",
        "                                                          batch_size=40,\n",
        "                                                          class_mode='categorical',\n",
        "                                                          # color_mode='grayscale',\n",
        "                                                          target_size=(256,256),\n",
        "                                                          subset='validation', seed=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ueQ8b0eukBoi"
      },
      "outputs": [],
      "source": [
        "# Apply callbacks :\n",
        "\n",
        "import datetime \n",
        "import tensorflow as tf\n",
        "  \n",
        "my_callbacks = []\n",
        "\n",
        "# logdir = os.path.join(\"/content/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "# my_callbacks.append(tensorboard_callback)\n",
        "\n",
        "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'model_from_scratch_best.hdf5', save_best_only=True, verbose=1)\n",
        "my_callbacks.append(save_best_callback)\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\n",
        "my_callbacks.append(early_stop_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5iuGSf2TzI_",
        "outputId": "b73bd27b-802b-4843-9e6b-3448aacb2772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 8.7828 - accuracy: 0.2202\n",
            "Epoch 00001: val_loss improved from inf to 2.11744, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 53s 795ms/step - loss: 8.7828 - accuracy: 0.2202 - val_loss: 2.1174 - val_accuracy: 0.4474\n",
            "Epoch 2/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 2.1640 - accuracy: 0.4501\n",
            "Epoch 00002: val_loss improved from 2.11744 to 1.55425, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 48s 785ms/step - loss: 2.1640 - accuracy: 0.4501 - val_loss: 1.5542 - val_accuracy: 0.5943\n",
            "Epoch 3/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.7530 - accuracy: 0.5364\n",
            "Epoch 00003: val_loss improved from 1.55425 to 1.14038, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 49s 794ms/step - loss: 1.7530 - accuracy: 0.5364 - val_loss: 1.1404 - val_accuracy: 0.7145\n",
            "Epoch 4/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.4668 - accuracy: 0.6077\n",
            "Epoch 00004: val_loss improved from 1.14038 to 1.07719, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 47s 770ms/step - loss: 1.4668 - accuracy: 0.6077 - val_loss: 1.0772 - val_accuracy: 0.7245\n",
            "Epoch 5/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.2995 - accuracy: 0.6638\n",
            "Epoch 00005: val_loss improved from 1.07719 to 0.87986, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 48s 775ms/step - loss: 1.2995 - accuracy: 0.6638 - val_loss: 0.8799 - val_accuracy: 0.7963\n",
            "Epoch 6/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 1.0916 - accuracy: 0.7053\n",
            "Epoch 00006: val_loss improved from 0.87986 to 0.77914, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 47s 769ms/step - loss: 1.0916 - accuracy: 0.7053 - val_loss: 0.7791 - val_accuracy: 0.7930\n",
            "Epoch 7/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.9757 - accuracy: 0.7334\n",
            "Epoch 00007: val_loss did not improve from 0.77914\n",
            "61/61 [==============================] - 45s 734ms/step - loss: 0.9757 - accuracy: 0.7334 - val_loss: 0.7798 - val_accuracy: 0.8264\n",
            "Epoch 8/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.9320 - accuracy: 0.7489\n",
            "Epoch 00008: val_loss improved from 0.77914 to 0.67124, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 750ms/step - loss: 0.9320 - accuracy: 0.7489 - val_loss: 0.6712 - val_accuracy: 0.8414\n",
            "Epoch 9/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.8436 - accuracy: 0.7676\n",
            "Epoch 00009: val_loss improved from 0.67124 to 0.67083, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 747ms/step - loss: 0.8436 - accuracy: 0.7676 - val_loss: 0.6708 - val_accuracy: 0.8247\n",
            "Epoch 10/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.8130 - accuracy: 0.7782\n",
            "Epoch 00010: val_loss improved from 0.67083 to 0.59619, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 747ms/step - loss: 0.8130 - accuracy: 0.7782 - val_loss: 0.5962 - val_accuracy: 0.8598\n",
            "Epoch 11/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.7965\n",
            "Epoch 00011: val_loss did not improve from 0.59619\n",
            "61/61 [==============================] - 45s 729ms/step - loss: 0.7466 - accuracy: 0.7965 - val_loss: 0.6509 - val_accuracy: 0.8214\n",
            "Epoch 12/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.8193\n",
            "Epoch 00012: val_loss improved from 0.59619 to 0.54556, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 749ms/step - loss: 0.6622 - accuracy: 0.8193 - val_loss: 0.5456 - val_accuracy: 0.8781\n",
            "Epoch 13/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.8217\n",
            "Epoch 00013: val_loss did not improve from 0.54556\n",
            "61/61 [==============================] - 45s 736ms/step - loss: 0.6769 - accuracy: 0.8217 - val_loss: 0.5799 - val_accuracy: 0.8514\n",
            "Epoch 14/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.8287\n",
            "Epoch 00014: val_loss improved from 0.54556 to 0.51974, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 746ms/step - loss: 0.6391 - accuracy: 0.8287 - val_loss: 0.5197 - val_accuracy: 0.8648\n",
            "Epoch 15/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.8437\n",
            "Epoch 00015: val_loss improved from 0.51974 to 0.50600, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 747ms/step - loss: 0.5568 - accuracy: 0.8437 - val_loss: 0.5060 - val_accuracy: 0.8681\n",
            "Epoch 16/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.8478\n",
            "Epoch 00016: val_loss improved from 0.50600 to 0.46094, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 745ms/step - loss: 0.5629 - accuracy: 0.8478 - val_loss: 0.4609 - val_accuracy: 0.8781\n",
            "Epoch 17/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.8539\n",
            "Epoch 00017: val_loss did not improve from 0.46094\n",
            "61/61 [==============================] - 45s 740ms/step - loss: 0.5581 - accuracy: 0.8539 - val_loss: 0.5394 - val_accuracy: 0.8731\n",
            "Epoch 18/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.8571\n",
            "Epoch 00018: val_loss did not improve from 0.46094\n",
            "61/61 [==============================] - 45s 738ms/step - loss: 0.4999 - accuracy: 0.8571 - val_loss: 0.5194 - val_accuracy: 0.8598\n",
            "Epoch 19/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8669\n",
            "Epoch 00019: val_loss improved from 0.46094 to 0.45322, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 49s 793ms/step - loss: 0.4966 - accuracy: 0.8669 - val_loss: 0.4532 - val_accuracy: 0.8932\n",
            "Epoch 20/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8767\n",
            "Epoch 00020: val_loss did not improve from 0.45322\n",
            "61/61 [==============================] - 45s 735ms/step - loss: 0.4792 - accuracy: 0.8767 - val_loss: 0.5117 - val_accuracy: 0.8648\n",
            "Epoch 21/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.8714\n",
            "Epoch 00021: val_loss did not improve from 0.45322\n",
            "61/61 [==============================] - 45s 729ms/step - loss: 0.4755 - accuracy: 0.8714 - val_loss: 0.4624 - val_accuracy: 0.8831\n",
            "Epoch 22/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.8812\n",
            "Epoch 00022: val_loss improved from 0.45322 to 0.43783, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 745ms/step - loss: 0.4290 - accuracy: 0.8812 - val_loss: 0.4378 - val_accuracy: 0.8798\n",
            "Epoch 23/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8897\n",
            "Epoch 00023: val_loss did not improve from 0.43783\n",
            "61/61 [==============================] - 45s 729ms/step - loss: 0.3998 - accuracy: 0.8897 - val_loss: 0.4682 - val_accuracy: 0.8748\n",
            "Epoch 24/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.8783\n",
            "Epoch 00024: val_loss improved from 0.43783 to 0.42606, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 745ms/step - loss: 0.4175 - accuracy: 0.8783 - val_loss: 0.4261 - val_accuracy: 0.8848\n",
            "Epoch 25/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8934\n",
            "Epoch 00025: val_loss did not improve from 0.42606\n",
            "61/61 [==============================] - 45s 730ms/step - loss: 0.3734 - accuracy: 0.8934 - val_loss: 0.4311 - val_accuracy: 0.8915\n",
            "Epoch 26/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.8909\n",
            "Epoch 00026: val_loss did not improve from 0.42606\n",
            "61/61 [==============================] - 45s 729ms/step - loss: 0.4019 - accuracy: 0.8909 - val_loss: 0.4447 - val_accuracy: 0.8848\n",
            "Epoch 27/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.8930\n",
            "Epoch 00027: val_loss improved from 0.42606 to 0.40097, saving model to model_from_scratch_best.hdf5\n",
            "61/61 [==============================] - 46s 744ms/step - loss: 0.4007 - accuracy: 0.8930 - val_loss: 0.4010 - val_accuracy: 0.8898\n",
            "Epoch 28/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.9035\n",
            "Epoch 00028: val_loss did not improve from 0.40097\n",
            "61/61 [==============================] - 45s 728ms/step - loss: 0.3842 - accuracy: 0.9035 - val_loss: 0.4156 - val_accuracy: 0.8865\n",
            "Epoch 29/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.8930\n",
            "Epoch 00029: val_loss did not improve from 0.40097\n",
            "61/61 [==============================] - 45s 730ms/step - loss: 0.3641 - accuracy: 0.8930 - val_loss: 0.4305 - val_accuracy: 0.9015\n",
            "Epoch 30/30\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.9072\n",
            "Epoch 00030: val_loss did not improve from 0.40097\n",
            "61/61 [==============================] - 45s 730ms/step - loss: 0.3606 - accuracy: 0.9072 - val_loss: 0.4087 - val_accuracy: 0.8781\n"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              # steps_per_epoch=50,\n",
        "                              steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
        "                              epochs=30,\n",
        "                              validation_steps=15,\n",
        "                              verbose=1,\n",
        "                              callbacks=my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BZANTHekSznu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8021cc-25fd-4692-bf1f-0cc5bba8197e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2149 images belonging to 34 classes.\n"
          ]
        }
      ],
      "source": [
        "# test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen  = ImageDataGenerator()\n",
        "# --------------------\n",
        "# Flow testing images in batches using test_datagen generator\n",
        "# --------------------\n",
        "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
        "                                                   batch_size=10,\n",
        "                                                   class_mode='categorical',\n",
        "                                                  #  color_mode='grayscale',\n",
        "                                                   target_size=(256,256))\n",
        "# # Testing the CNN on testing data : \n",
        "# loss, acc = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q3PTISh9XtGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "6888dd17-f57a-4bdd-d40b-ce26854fc1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 3s 13ms/step - loss: 1.5091 - accuracy: 0.7436\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Testing the CNN on testing data : \n",
        "loss, acc = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading the best state model from the content folder : \n",
        "\n",
        "model_saved = models.load_model('/content/model_from_scratch_best.hdf5')\n",
        "model_saved.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmXJP6VsLlS9",
        "outputId": "3fb9c37d-d245-471d-fb09-f733e747b64c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                34850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,856,162\n",
            "Trainable params: 25,856,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " loss_saved, acc_saved = model_saved.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD96ihm6LwpB",
        "outputId": "f89786b1-7747-4305-c192-fad10256abe5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 3s 14ms/step - loss: 1.5356 - accuracy: 0.7003\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CV_Project_4_NOT_pretrained.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpPIn/rY3DZSP0U9QEhW9j"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}